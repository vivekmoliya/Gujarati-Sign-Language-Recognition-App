# Gujarati Sign Language Recognition

This project is an AI-powered web application that recognizes **Gujarati Sign Language (Vyanjan)** gestures from camera-captured images and converts them into text. Built with **Flask**, **CNN-based model**, and optionally **MediaPipe**, the app helps improve communication for the deaf and hard-of-hearing community.


## ğŸš€ Features

- ğŸ“· Live camera input for gesture recognition
- ğŸ¤– Trained CNN model to classify Gujarati sign language letters
- ğŸ§  Optionally supports hand detection using MediaPipe (experimental)
- ğŸŒ User-friendly Flask web interface
- âœ… Real-time prediction and result display


## ğŸ§ª Dataset Structure

dataset/ â”‚ â”œâ”€â”€ train/ â”‚ â”œâ”€â”€ àª•/ (12 images) â”‚ â”œâ”€â”€ àª–/ â”‚ â””â”€â”€ ... (34 vyanjans total) â”‚ â”œâ”€â”€ test_data/ â”‚ â””â”€â”€ test/ â”‚ â”œâ”€â”€ test(1).jpg â”‚ â”œâ”€â”€ test(2).jpg â”‚ â””â”€â”€ ...


Each class has hand sign images for training. Test images are unlabeled.


## ğŸ§  Model Training

- Preprocessed images to standard sizes (`256x256` and `512x512`)
- Augmented using rotation (0Â°, 90Â°, 180Â°, 270Â°)
- Model trained using a CNN with high accuracy (~90% without MediaPipe)
- MediaPipe was also tested for hand segmentation, but resulted in lower accuracy (~70%) due to input mismatch.


## ğŸ› ï¸ Tech Stack

- **Frontend**: HTML5, CSS3, JavaScript
- **Backend**: Python, Flask
- **ML/DL**: TensorFlow / Keras, OpenCV

